{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import codecs\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "tagger = MeCab.Tagger('-Owakati')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec ./data/sample-input.txt\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "wakati_file = \"wakati.txt\"\n",
    "if(os.path.exists(wakati_file)):\n",
    "    os.remove(wakati_file )\n",
    "\n",
    "files = glob.glob('./data/*.txt')\n",
    "\n",
    "wakati = open(wakati_file , 'a')\n",
    "for file in files:\n",
    "    print(\"exec \" + file)\n",
    "    input_text = \"\"\n",
    "    with open(file, 'r') as f:\n",
    "        input_text = f.read()\n",
    "    wakati_text = tagger.parse(input_text)\n",
    "    wakati.write(wakati_text)\n",
    "wakati.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-21 10:19:36,057 : INFO : collecting all words and their counts\n",
      "2018-01-21 10:19:36,063 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-21 10:19:36,065 : INFO : collected 393 word types from a corpus of 1468 raw words and 1 sentences\n",
      "2018-01-21 10:19:36,066 : INFO : Loading a fresh vocabulary\n",
      "2018-01-21 10:19:36,068 : INFO : min_count=5 retains 61 unique words (15% of original 393, drops 332)\n",
      "2018-01-21 10:19:36,069 : INFO : min_count=5 leaves 965 word corpus (65% of original 1468, drops 503)\n",
      "2018-01-21 10:19:36,070 : INFO : deleting the raw counts dictionary of 393 items\n",
      "2018-01-21 10:19:36,071 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2018-01-21 10:19:36,072 : INFO : downsampling leaves estimated 275 word corpus (28.6% of prior 965)\n",
      "2018-01-21 10:19:36,074 : INFO : estimated required memory for 61 words and 100 dimensions: 79300 bytes\n",
      "2018-01-21 10:19:36,075 : INFO : resetting layer weights\n",
      "2018-01-21 10:19:36,080 : INFO : training model with 3 workers on 61 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-01-21 10:19:36,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-01-21 10:19:36,113 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-21 10:19:36,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-21 10:19:36,117 : INFO : training on 7340 raw words (1348 effective words) took 0.0s, 39705 effective words/s\n",
      "2018-01-21 10:19:36,119 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "sentences = word2vec.Text8Corpus(wakati_file )\n",
    "model = word2vec.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('人間', -0.041407886892557144),\n",
      " ('技法', -0.06211541220545769),\n",
      " ('特徴', -0.08734170347452164),\n",
      " ('その', -0.12136419862508774),\n",
      " ('ない', -0.13313762843608856),\n",
      " ('性能', -0.14809203147888184),\n",
      " ('マイニング', -0.1504712700843811),\n",
      " ('データ', -0.15087419748306274),\n",
      " ('と', -0.15397316217422485),\n",
      " ('いる', -0.15555566549301147)]\n"
     ]
    }
   ],
   "source": [
    "pprint(model.wv.most_similar(positive=[ 'アルゴリズム'], negative=['学習']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
